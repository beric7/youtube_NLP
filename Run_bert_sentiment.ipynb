{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Run_bert_sentiment.ipynb","provenance":[],"mount_file_id":"1Q1dMP_X90nfM1dt9jYaXc6CPiu3Udj5_","authorship_tag":"ABX9TyOoX2i69uLR++qz5VH5+Byw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"yFv5t47VF8my","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607456133506,"user_tz":300,"elapsed":4891,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}},"outputId":"5b543685-236b-4095-e243-8ef289b9856f"},"source":["!pip install -q -U watermark\n","!pip install -qq transformers\n","%reload_ext watermark\n","%watermark -v -p numpy,pandas,torch,transformers"],"execution_count":16,"outputs":[{"output_type":"stream","text":["CPython 3.6.9\n","IPython 5.5.0\n","\n","numpy 1.18.5\n","pandas 1.1.4\n","torch 1.7.0+cu101\n","transformers 4.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dAnT7M1x2aUm","executionInfo":{"status":"ok","timestamp":1607456133507,"user_tz":300,"elapsed":4882,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}},"outputId":"224ddc54-6a8a-4853-984d-4f1ac0323888"},"source":["import sys\r\n","from google.colab import drive\r\n","drive.mount('/content/gdrive/')\r\n","# modify \"customized_path_to_homework\", path of folder in drive, where you uploaded your homework\r\n","prefix = '/content/gdrive/Shared drives/Deep Learning Final Project/'\r\n","sys.path.append(prefix)\r\n","print(sys.path)\r\n","print(prefix)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n","['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython', '/content/gdrive/Shared drives/Deep Learning Final Project/', '/content/gdrive/Shared drives/Deep Learning Final Project/']\n","/content/gdrive/Shared drives/Deep Learning Final Project/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"usaI0d4BGKoq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607456133723,"user_tz":300,"elapsed":5092,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}},"outputId":"63e5ff6d-54e0-4869-d9e6-f9b4655a945a"},"source":["import transformers\n","from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n","import torch\n","\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from pylab import rcParams\n","import matplotlib.pyplot as plt\n","from matplotlib import rc\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, classification_report\n","from collections import defaultdict\n","from textwrap import wrap\n","\n","from torch import nn, optim\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","\n","%matplotlib inline\n","%config InlineBackend.figure_format='retina'\n","\n","sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n","\n","HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n","\n","sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n","\n","rcParams['figure.figsize'] = 12, 8\n","\n","RANDOM_SEED = 42\n","np.random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)\n","\n","import torch\n","import pandas as pd\n","import transformers\n","import numpy as np\n","# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# device = torch.device('cuda')\n","print(torch.__version__)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["1.7.0+cu101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ObybqjVJGZ6C","executionInfo":{"status":"ok","timestamp":1607456133724,"user_tz":300,"elapsed":5087,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}}},"source":["class_names = ['1', '2', '3']"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"_A1_0pVbGe7c","executionInfo":{"status":"ok","timestamp":1607456133725,"user_tz":300,"elapsed":5083,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}}},"source":["PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"EnfpIUUAGrT5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607456136173,"user_tz":300,"elapsed":7526,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}},"outputId":"19addec5-8cac-43a7-e952-c7f325d184a5"},"source":["! pip install pytorch-pretrained-bert\n","\n","tokenizer = transformers.BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.16.31)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.7.0+cu101)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n","Requirement already satisfied: botocore<1.20.0,>=1.19.31 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.19.31)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.8)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.11.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.31->boto3->pytorch-pretrained-bert) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.31->boto3->pytorch-pretrained-bert) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x6D-qDLWGx3b","executionInfo":{"status":"ok","timestamp":1607456136178,"user_tz":300,"elapsed":7525,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}}},"source":["sample_txt = 'When was I last outside? I am stuck at home for 2 weeks.'"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"xjYtDt3rGtln","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607456136179,"user_tz":300,"elapsed":7521,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}},"outputId":"ab8f7dd3-f47e-4884-e55a-33ed3d828ec9"},"source":["tokens = tokenizer.tokenize(sample_txt)\n","token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","print(f' Sentence: {sample_txt}')\n","print(f'   Tokens: {tokens}')\n","print(f'Token IDs: {token_ids}')"],"execution_count":23,"outputs":[{"output_type":"stream","text":[" Sentence: When was I last outside? I am stuck at home for 2 weeks.\n","   Tokens: ['When', 'was', 'I', 'last', 'outside', '?', 'I', 'am', 'stuck', 'at', 'home', 'for', '2', 'weeks', '.']\n","Token IDs: [1332, 1108, 146, 1314, 1796, 136, 146, 1821, 5342, 1120, 1313, 1111, 123, 2277, 119]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a1rwlwP5HB1l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607456136180,"user_tz":300,"elapsed":7516,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}},"outputId":"08775fbb-730d-4265-b1e0-04a2d80c52b0"},"source":["encoding = tokenizer.encode_plus(\n","  sample_txt,\n","  max_length=32,\n","  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n","  return_token_type_ids=False,\n","  pad_to_max_length=True,\n","  return_attention_mask=True,\n","  return_tensors='pt',  # Return PyTorch tensors\n",")\n","\n","encoding.keys()"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["dict_keys(['input_ids', 'attention_mask'])"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"K3n8WcK7HP42","executionInfo":{"status":"ok","timestamp":1607456136180,"user_tz":300,"elapsed":7509,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}}},"source":["MAX_LEN = 160"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"V3w4sJkBHUpE","executionInfo":{"status":"ok","timestamp":1607456136181,"user_tz":300,"elapsed":7505,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}}},"source":["class GPReviewDataset(Dataset):\n","\n","  def __init__(self, reviews, targets, tokenizer, max_len):\n","    self.reviews = reviews\n","    self.targets = targets\n","    self.tokenizer = tokenizer\n","    self.max_len = max_len\n","  \n","  def __len__(self):\n","    return len(self.reviews)\n","  \n","  def __getitem__(self, item):\n","    review = str(self.reviews[item])\n","    target = self.targets[item]\n","\n","    encoding = self.tokenizer.encode_plus(\n","      review,\n","      add_special_tokens=True,\n","      max_length=self.max_len,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      return_attention_mask=True,\n","      return_tensors='pt',\n","    )\n","\n","    return {\n","      'review_text': review,\n","      'input_ids': encoding['input_ids'].flatten(),\n","      'attention_mask': encoding['attention_mask'].flatten(),\n","      'targets': torch.tensor(target, dtype=torch.long)\n","    }"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"dpHkdKokHs2A","executionInfo":{"status":"ok","timestamp":1607456136182,"user_tz":300,"elapsed":7502,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}}},"source":["class SentimentClassifier(nn.Module):\n","\n","  def __init__(self, n_classes):\n","    super(SentimentClassifier, self).__init__()\n","    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n","    self.drop = nn.Dropout(p=0.3)\n","    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n","  \n","  def forward(self, input_ids, attention_mask):\n","    _, pooled_output = self.bert(\n","      input_ids=input_ids,\n","      attention_mask=attention_mask\n","    )\n","    output = self.drop(pooled_output)\n","    return self.out(output)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"UK7KhhnNHvIc","executionInfo":{"status":"ok","timestamp":1607456139362,"user_tz":300,"elapsed":10678,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}}},"source":["class_names = ['1', '2', '3']\n","model = SentimentClassifier(len(class_names))\n","model = model.to(device)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"UoePJ8-QH4-j","executionInfo":{"status":"ok","timestamp":1607456139363,"user_tz":300,"elapsed":10675,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}}},"source":["def eval_model(model, data_loader, loss_fn, device, n_examples):\n","  model = model.eval()\n","\n","  losses = []\n","  correct_predictions = 0\n","\n","  with torch.no_grad():\n","    for d in data_loader:\n","      input_ids = d[\"input_ids\"].to(device)\n","      attention_mask = d[\"attention_mask\"].to(device)\n","      targets = d[\"targets\"].to(device)\n","\n","      outputs = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask\n","      )\n","      _, preds = torch.max(outputs, dim=1)\n","\n","      loss = loss_fn(outputs, targets)\n","\n","      correct_predictions += torch.sum(preds == targets)\n","      losses.append(loss.item())\n","\n","  return correct_predictions.double() / n_examples, np.mean(losses)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"-7BXQsxKIUdd","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"error","timestamp":1607456154649,"user_tz":300,"elapsed":25955,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}},"outputId":"a65dd731-5984-4982-d933-8e460d8150a8"},"source":["model = SentimentClassifier(len(class_names))\n","model.to(device)\n","model_path = '/content/gdrive/Shared drives/Deep Learning Final Project/' + 'best_bert_sentiment_model_state.bin'\n","model.load_state_dict(torch.load(model_path))"],"execution_count":30,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-b82b7478eb9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/gdrive/Shared drives/Deep Learning Final Project/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'best_bert_sentiment_model_state.bin'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'test_data_loader' is not defined"]}]},{"cell_type":"code","metadata":{"id":"PUFwf1vqIYTw","executionInfo":{"status":"ok","timestamp":1607456165303,"user_tz":300,"elapsed":495,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}}},"source":["def get_predictions(model, data_loader):\n","  model = model.eval()\n","  \n","  review_texts = []\n","  predictions = []\n","  prediction_probs = []\n","  real_values = []\n","\n","  with torch.no_grad():\n","    for d in data_loader:\n","\n","      texts = d[\"review_text\"]\n","      input_ids = d[\"input_ids\"].to(device)\n","      attention_mask = d[\"attention_mask\"].to(device)\n","      targets = d[\"targets\"].to(device)\n","\n","      outputs = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask\n","      )\n","      _, preds = torch.max(outputs, dim=1)\n","\n","      probs = F.softmax(outputs, dim=1)\n","\n","      review_texts.extend(texts)\n","      predictions.extend(preds)\n","      prediction_probs.extend(probs)\n","      real_values.extend(targets)\n","\n","  predictions = torch.stack(predictions).cpu()\n","  prediction_probs = torch.stack(prediction_probs).cpu()\n","  real_values = torch.stack(real_values).cpu()\n","  return review_texts, predictions, prediction_probs, real_values"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"78LdmwHhL8bQ","executionInfo":{"status":"ok","timestamp":1607456194216,"user_tz":300,"elapsed":430,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}}},"source":["review_text = \"dumb and ugly enwards\""],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"fPOXSUPUMAHz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607456194419,"user_tz":300,"elapsed":223,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}},"outputId":"63f8afe7-c27b-44fa-c482-2fe475857191"},"source":["encoded_review = tokenizer.encode_plus(\n","  review_text,\n","  max_length=MAX_LEN,\n","  add_special_tokens=True,\n","  return_token_type_ids=False,\n","  pad_to_max_length=True,\n","  return_attention_mask=True,\n","  return_tensors='pt',\n",")"],"execution_count":36,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"40pnFaLYMCAE","colab":{"base_uri":"https://localhost:8080/","height":782},"executionInfo":{"status":"error","timestamp":1607456502606,"user_tz":300,"elapsed":438,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}},"outputId":"7df8d5e6-e1d3-4cd0-9db9-92e2da2146bf"},"source":["input_ids = encoded_review['input_ids'].to(device)\n","attention_mask = encoded_review['attention_mask'].to(device)\n","print(input_ids)\n","print(attention_mask)\n","output = model(input_ids, attention_mask)\n","_, prediction = torch.max(output, dim=1)\n","\n","print(f'Review text: {review_text}')\n","print(f'Sentiment  : {class_names[prediction]}')"],"execution_count":40,"outputs":[{"output_type":"stream","text":["tensor([[  101, 14908,  1105, 10126,  4035,  5984,  1116,   102,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n","       device='cuda:0')\n","tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n"],"name":"stdout"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-9a63d5ccd762>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-27-64dc92491dcb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     )\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m    981\u001b[0m     return (_VF.dropout_(input, p, training)\n\u001b[1;32m    982\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m             else _VF.dropout(input, p, training))\n\u001b[0m\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: dropout(): argument 'input' (position 1) must be Tensor, not str"]}]}]}